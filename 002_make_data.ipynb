{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed8961c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Japanese_BPEEncoder_V2'...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aad566",
   "metadata": {},
   "source": [
    "# CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43102bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_WORD_IMAGE_ONLY = True\n",
    "REAL_IMAGE_ONLY = True\n",
    "REAL_IMAGE_THRESHOLD = 0.75\n",
    "NO_UNIQUE_NOUN_SENTENCE_ONLY = True\n",
    "\n",
    "VOCAB_SIZE = 8192\n",
    "MAX_SENTENCE_LENGTH = 31\n",
    "MIN_SENTENCE_LENGTH = 4\n",
    "MIN_FREEQENCY = 16\n",
    "\n",
    "data_dir = f\"../datas/{NO_WORD_IMAGE_ONLY}_{REAL_IMAGE_ONLY}_{REAL_IMAGE_THRESHOLD}_{NO_UNIQUE_NOUN_SENTENCE_ONLY}_{VOCAB_SIZE}_{MAX_SENTENCE_LENGTH}_{MIN_SENTENCE_LENGTH}_{MIN_FREEQENCY}/\"\n",
    "if os.path.exists(data_dir):\n",
    "    shutil.rmtree(data_dir)\n",
    "os.mkdir(data_dir)\n",
    "with open(f\"{data_dir}data_config.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"NO_WORD_IMAGE_ONLY\": NO_WORD_IMAGE_ONLY,\n",
    "        \"REAL_IMAGE_ONLY\": REAL_IMAGE_ONLY,\n",
    "        \"REAL_IMAGE_THRESHOLD\": REAL_IMAGE_THRESHOLD,\n",
    "        \"NO_UNIQUE_NOUN_SENTENCE_ONLY\": NO_UNIQUE_NOUN_SENTENCE_ONLY,\n",
    "\n",
    "        \"VOCAB_SIZE\": VOCAB_SIZE,\n",
    "        \"MAX_SENTENCE_LENGTH\": MAX_SENTENCE_LENGTH,\n",
    "        \"MIN_SENTENCE_LENGTH\": MIN_SENTENCE_LENGTH,\n",
    "        \"MIN_FREEQENCY\": MIN_FREEQENCY\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
<<<<<<< Updated upstream
   "id": "b9e3a0d7",
=======
   "id": "41fe640c",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "100%|██████████| 602566/602566 [03:05<00:00, 3242.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237894/237894 [00:12<00:00, 19173.45it/s]\n"
=======
      "100%|██████████| 602566/602566 [05:25<00:00, 1848.89it/s]\n",
      "100%|██████████| 220138/220138 [00:07<00:00, 31210.75it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "data": {
      "text/plain": [
       "(237894, 1401811, 8192, [0, 1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"../datas/Bokete_Dataset/boke_data_assemble/\"\n",
    "IMAGE_DIR = \"../datas/Bokete_Dataset/boke_image/\"\n",
    "\n",
    "data_dict = dict()\n",
    "\n",
    "def is_contains_invalid_characters(text):\n",
    "    # ひらがな（\\u3040-\\u309F）\n",
    "    # カタカナ（\\u30A0-\\u30FF）\n",
    "    # 漢字（\\u4E00-\\u9FFF）\n",
    "    # 句読点「、。」（直接列挙）\n",
    "    pattern = r\"^[\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF、。!?！？ー]*$\"\n",
    "    return not re.fullmatch(pattern, text)\n",
    "\n",
    "for JP in tqdm(os.listdir(DATA_DIR)):\n",
    "\n",
    "    # 画像があるか\n",
    "    n = JP.split(\".\")[0]\n",
    "    if not os.path.exists(f\"{IMAGE_DIR}{n}.jpg\"):\n",
    "        continue\n",
    "\n",
    "    with open(f\"{DATA_DIR}{JP}\", \"r\") as f:\n",
    "        d = json.load(f)\n",
    "    \n",
    "    image_information = d[\"image_infomation\"]\n",
    "\n",
    "    # 現実の画像であるか\n",
    "    if REAL_IMAGE_ONLY:\n",
    "        if image_information[\"is_photographic_probability\"] < REAL_IMAGE_THRESHOLD:\n",
    "            continue\n",
    "    \n",
    "    # OCRで文字を含む画像であるか\n",
    "    if NO_WORD_IMAGE_ONLY:\n",
    "        if len(image_information[\"ocr\"]) != 0:\n",
    "            continue\n",
    "    \n",
    "    tmp_bokes = list()\n",
    "    for B in d[\"bokes\"]:\n",
    "\n",
    "        # 数字，ローマ字，記号を含む文章であるか\n",
    "        if is_contains_invalid_characters(B[\"boke\"]):\n",
    "            continue\n",
    "        \n",
    "        # 固有名詞を含む文章であるか\n",
    "        if NO_UNIQUE_NOUN_SENTENCE_ONLY:\n",
    "            if len(B[\"unique_nouns\"]) != 0:\n",
    "                continue\n",
    "            \n",
    "        tmp_bokes.append( B[\"boke\"] )\n",
    "\n",
    "    data_dict[n] = tmp_bokes\n",
    "\n",
    "# トークナイザーの学習\n",
    "corpus = list()\n",
    "for V in data_dict.values(): corpus += V\n",
    "tokenizer = Tokenizer(BPE())\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(vocab_size = VOCAB_SIZE, \n",
    "                     special_tokens = [\"[PAD]\", \"[BOS]\", \"[EOS]\"],\n",
    "                     min_frequency = MIN_FREEQENCY)\n",
    "tokenizer.train_from_iterator(corpus, trainer)\n",
    "\n",
    "tmp_data_dict = dict()\n",
    "for K, V in tqdm(data_dict.items()):\n",
    "    tmp_bokes = list()\n",
    "    for B in V:\n",
    "        tokenized_boke = tokenizer.encode(B)\n",
    "        if not (MIN_SENTENCE_LENGTH <= len(tokenized_boke.tokens) <= MAX_SENTENCE_LENGTH):\n",
    "            continue\n",
    "        tmp_bokes.append(B)\n",
    "    \n",
    "    tmp_data_dict[K] = tmp_bokes\n",
    "data_dict = tmp_data_dict\n",
    "\n",
    "#\n",
    "len(data_dict), sum([len(V) for V in data_dict.values()]), len(tokenizer.get_vocab()), tokenizer.encode(\"[PAD][BOS][EOS]\").ids"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 6,
=======
   "execution_count": 4,
>>>>>>> Stashed changes
   "id": "d0d0a04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "100%|██████████| 235515/235515 [00:13<00:00, 16968.72it/s]\n",
      "100%|██████████| 2379/2379 [00:00<00:00, 21519.18it/s]\n"
=======
      "100%|██████████| 217936/217936 [00:03<00:00, 60525.96it/s] \n",
      "100%|██████████| 2202/2202 [00:00<00:00, 131332.94it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "data": {
      "text/plain": [
       "(235515, 2379, (1388020, 32))"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 6,
=======
     "execution_count": 4,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_numbers, test_image_numbers = train_test_split(list(data_dict.keys()), test_size = 0.01)\n",
    "\n",
    "# image\n",
    "train_inputs_1 = list()\n",
    "# sentence\n",
    "train_inputs_2 = list()\n",
    "train_teacher_signals = list()\n",
    "for N in tqdm(train_image_numbers):\n",
    "    for B in data_dict[N]:\n",
    "\n",
    "        train_inputs_1.append( int(N) )\n",
    "\n",
    "        tokenized_boke = [1] + tokenizer.encode(B).ids + [2]\n",
    "        tokenized_boke += [0] * (MAX_SENTENCE_LENGTH + 2 - len(tokenized_boke))\n",
    "        train_inputs_2.append( tokenized_boke[:-1] )\n",
    "        train_teacher_signals.append( tokenized_boke[1:] )\n",
    "train_inputs_1 = np.array(train_inputs_1)\n",
    "train_inputs_2 = np.array(train_inputs_2)\n",
    "train_teacher_signals = np.array(train_teacher_signals)\n",
    "\n",
    "#\n",
    "# image\n",
    "test_inputs_1 = list()\n",
    "# sentence\n",
    "test_inputs_2 = list()\n",
    "test_teacher_signals = list()\n",
    "for N in tqdm(test_image_numbers):\n",
    "    for B in data_dict[N]:\n",
    "\n",
    "        test_inputs_1.append( int(N) )\n",
    "\n",
    "        tokenized_boke = [1] + tokenizer.encode(B).ids + [2]\n",
    "        tokenized_boke += [0] * (MAX_SENTENCE_LENGTH + 2 - len(tokenized_boke))\n",
    "        test_inputs_2.append( tokenized_boke[:-1] )\n",
    "        test_teacher_signals.append( tokenized_boke[1:] )\n",
    "test_inputs_1 = np.array(test_inputs_1)\n",
    "test_inputs_2 = np.array(test_inputs_2)\n",
    "test_teacher_signals = np.array(test_teacher_signals)\n",
    "\n",
    "#\n",
    "len(train_image_numbers), len(test_image_numbers), train_inputs_2.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 7,
=======
   "execution_count": 5,
>>>>>>> Stashed changes
   "id": "c4ccccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(f\"{data_dir}tokenizer.json\")\n",
    "np.save(f\"{data_dir}train_inputs_1.npy\", train_inputs_1)\n",
    "np.save(f\"{data_dir}train_inputs_2.npy\", train_inputs_2)\n",
    "np.save(f\"{data_dir}train_teacher_signals.npy\", train_teacher_signals)\n",
    "np.save(f\"{data_dir}test_inputs_1.npy\", test_inputs_1)\n",
    "np.save(f\"{data_dir}test_inputs_2.npy\", test_inputs_2)\n",
    "np.save(f\"{data_dir}test_teacher_signals.npy\", test_teacher_signals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Colab_20250113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
